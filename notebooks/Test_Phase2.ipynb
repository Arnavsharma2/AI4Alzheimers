{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ CogniSense Phase 2 Test Notebook\n",
    "\n",
    "This notebook tests the training infrastructure to ensure everything works correctly.\n",
    "\n",
    "**Expected Result**: All tests pass ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers datasets\n",
    "!pip install pillow numpy pandas matplotlib seaborn\n",
    "!pip install scikit-learn scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "import os\n",
    "if not os.path.exists('AI4Alzheimers'):\n",
    "    !git clone https://github.com/Arnavsharma2/AI4Alzheimers.git\n",
    "    %cd AI4Alzheimers\n",
    "else:\n",
    "    %cd AI4Alzheimers\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comprehensive Phase 2 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the automated test suite\n",
    "!python test_phase2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Test: Quick Training Run\n",
    "\n",
    "Let's run a quick training session to verify everything works end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training test (5 epochs, small dataset)\n",
    "!python train.py --mode fusion --epochs 5 --num-samples 50 --batch-size 8 --save-dir ./test_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check that checkpoint was created\n",
    "checkpoint_path = './test_checkpoints/fusion/best_model.pt'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"‚úÖ Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Check file size\n",
    "    size_mb = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "    print(f\"   Size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå Checkpoint not found!\")\n",
    "\n",
    "# Check training history\n",
    "history_path = './test_checkpoints/fusion/training_history.json'\n",
    "if os.path.exists(history_path):\n",
    "    print(f\"\\n‚úÖ Training history saved: {history_path}\")\n",
    "    \n",
    "    with open(history_path) as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    print(f\"   Epochs trained: {len(history['train_loss'])}\")\n",
    "    print(f\"   Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "    print(f\"   Final val loss: {history['val_loss'][-1]:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Training history not found!\")\n",
    "\n",
    "# Check test metrics\n",
    "metrics_path = './test_checkpoints/fusion/test_metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    print(f\"\\n‚úÖ Test metrics saved: {metrics_path}\")\n",
    "    \n",
    "    with open(metrics_path) as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Test metrics not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Individual Modality Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training a single modality (eye tracking)\n",
    "!python train.py --mode single --modality eye --epochs 3 --num-samples 40 --batch-size 8 --save-dir ./test_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify eye model checkpoint\n",
    "eye_checkpoint = './test_checkpoints/eye/best_model.pt'\n",
    "if os.path.exists(eye_checkpoint):\n",
    "    print(f\"‚úÖ Eye model checkpoint saved\")\n",
    "    \n",
    "    # Load and check metrics\n",
    "    with open('./test_checkpoints/eye/test_metrics.json') as f:\n",
    "        eye_metrics = json.load(f)\n",
    "    \n",
    "    print(\"\\nEye Tracking Model Performance:\")\n",
    "    print(f\"  Accuracy: {eye_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  AUC: {eye_metrics['auc']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Eye model checkpoint not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "with open('./test_checkpoints/fusion/training_history.json') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax = axes[0]\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "ax.plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
    "ax.plot(epochs, history['val_loss'], 'r-o', label='Val Loss', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training Progress - Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax = axes[1]\n",
    "train_accs = [m['accuracy'] for m in history['train_metrics']]\n",
    "val_accs = [m['accuracy'] for m in history['val_metrics']]\n",
    "ax.plot(epochs, train_accs, 'b-o', label='Train Accuracy', linewidth=2)\n",
    "ax.plot(epochs, val_accs, 'r-o', label='Val Accuracy', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Training Progress - Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.fusion.fusion_model import MultimodalFusionModel\n",
    "from src.data_processing.synthetic_data_generator import (\n",
    "    EyeTrackingGenerator,\n",
    "    TypingDynamicsGenerator,\n",
    "    ClockDrawingGenerator,\n",
    "    GaitDataGenerator\n",
    ")\n",
    "from transformers import ViTImageProcessor\n",
    "\n",
    "# Load trained model\n",
    "model = MultimodalFusionModel(\n",
    "    speech_config={'freeze_encoders': True},\n",
    "    drawing_config={'freeze_encoder': True},\n",
    "    fusion_type='attention'\n",
    ")\n",
    "\n",
    "checkpoint = torch.load('./test_checkpoints/fusion/best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Trained model loaded successfully\")\n",
    "print(f\"   Trained for {checkpoint['epoch']} epochs\")\n",
    "print(f\"   Val metrics: {checkpoint['metrics']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new samples\n",
    "eye_gen = EyeTrackingGenerator()\n",
    "typing_gen = TypingDynamicsGenerator()\n",
    "clock_gen = ClockDrawingGenerator()\n",
    "gait_gen = GaitDataGenerator()\n",
    "vit_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "def test_sample(is_ad=False):\n",
    "    \"\"\"Generate and test a sample\"\"\"\n",
    "    # Generate data\n",
    "    eye_data = eye_gen.generate_sequence(is_alzheimers=is_ad)\n",
    "    typing_data = typing_gen.generate_sequence(is_alzheimers=is_ad)\n",
    "    clock_img = clock_gen.generate_image(is_alzheimers=is_ad)\n",
    "    gait_data = gait_gen.generate_sequence(is_alzheimers=is_ad)\n",
    "    \n",
    "    # Prepare inputs\n",
    "    eye_tensor = torch.FloatTensor(eye_data).unsqueeze(0)\n",
    "    typing_tensor = torch.FloatTensor(typing_data).unsqueeze(0)\n",
    "    clock_processed = vit_processor(images=clock_img, return_tensors=\"pt\")\n",
    "    drawing_tensor = clock_processed['pixel_values']\n",
    "    gait_tensor = torch.FloatTensor(gait_data).unsqueeze(0)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        risk_score, attention_weights, _ = model(\n",
    "            eye_gaze=eye_tensor,\n",
    "            typing_sequence=typing_tensor,\n",
    "            drawing_image=drawing_tensor,\n",
    "            gait_sensor=gait_tensor,\n",
    "            return_attention=True,\n",
    "            return_modality_features=True\n",
    "        )\n",
    "    \n",
    "    return risk_score.item(), attention_weights[0].cpu().numpy(), clock_img\n",
    "\n",
    "# Test Control sample\n",
    "risk_control, att_control, clock_control = test_sample(is_ad=False)\n",
    "print(f\"üîµ CONTROL Sample:\")\n",
    "print(f\"   Risk Score: {risk_control*100:.1f}%\")\n",
    "print(f\"   Expected: Low risk (<30%)\")\n",
    "\n",
    "# Test AD sample\n",
    "risk_ad, att_ad, clock_ad = test_sample(is_ad=True)\n",
    "print(f\"\\nüî¥ AD Sample:\")\n",
    "print(f\"   Risk Score: {risk_ad*100:.1f}%\")\n",
    "print(f\"   Expected: High risk (>70%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Model inference working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Phase 2 Test Summary\n",
    "\n",
    "If all cells above executed successfully, Phase 2 is **fully functional**!\n",
    "\n",
    "### What Works:\n",
    "- ‚úÖ Training infrastructure (dataset, dataloader, collate)\n",
    "- ‚úÖ Training loop (forward, backward, optimize)\n",
    "- ‚úÖ Validation and metrics computation\n",
    "- ‚úÖ Early stopping mechanism\n",
    "- ‚úÖ Model checkpointing\n",
    "- ‚úÖ Training history logging\n",
    "- ‚úÖ Both fusion and single modality training\n",
    "- ‚úÖ Model loading and inference\n",
    "\n",
    "### Next Steps:\n",
    "1. ‚úÖ Phase 1 (Demo) - Complete\n",
    "2. ‚úÖ Phase 2 (Training) - Complete\n",
    "3. ‚è≠Ô∏è Phase 3 (Preprocessing) - Skip (using synthetic data)\n",
    "4. ‚è≠Ô∏è Phase 4 (Visualization) - Next\n",
    "5. ‚è≠Ô∏è Phase 5 (Generate Results) - Priority\n",
    "6. ‚è≠Ô∏è Phase 6 (PDF Report) - Final\n",
    "\n",
    "Ready to proceed to the next phase!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
